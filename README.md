# ðŸ©º Aegis-Sphere â€” AI-Powered Oncology Decision Support
> Zero-cloud oncology: A multi-agent virtual tumor board engineered for the 8GB edge.
> **Offline, dual-mode clinical intelligence for LMIC clinics.**  
> Aegis-Sphere listens to TB/HIV consultations in real time, auto-detects malignancy signals, convenes a multi-agent virtual tumor board, routes treatment plans around drug shortages, and generates empathetic patient handouts â€” all on **8 GB VRAM**.

[![Kaggle Competition](https://img.shields.io/badge/Kaggle-Med--Gemma%20Impact%20Challenge-blue?logo=kaggle)](https://www.kaggle.com/competitions/med-gemma-impact-challenge)
[![Python](https://img.shields.io/badge/Python-3.10%2B-blue?logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.x-red?logo=streamlit)](https://streamlit.io/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ðŸŒ The Problem: Dr. Priya's Day

Dr. Priya sees **40 patients daily** at a district HIV clinic in Nagpur, India. When a 38-year-old HIV+ man presents with a 4-week wet cough, weight loss, and cervical lymphadenopathy, she correctly suspects TB â€” but misses that HIV+ patients have an **11.5Ã— standardised incidence ratio for NHL**.

| âŒ Before Aegis-Sphere | âœ… After Aegis-Sphere |
|---|---|
| Suspects TB, starts empiric RHEZ therapy | Ambient system detects oncology signals within 60s |
| Patient misclassified for 4â€“7 weeks | Auto-escalation: "HIV-related malignancy detected" |
| Lymphoma diagnosed at Stage IV | Virtual tumor board: staging + pathways generated |
| R-CHOP prescribed â€” Rituximab out of stock | TxGemma checks inventory â†’ CHOP + Liposomal Dox substituted |
| Patient leaves with no explanation | Grade-5 empathetic patient handout generated |
| No audit trail | Override records synced to big-center board for annotation |

---

## ðŸŽ¯ Impact Metrics

| Metric | Value |
|---|---|
| Early diagnoses/yr (500 pilot clinics) | **7,500** |
| Survival delta (Stage IIB vs IV NHL) | **+30â€“35%** |
| Drug waste reduction | **âˆ’20%** |
| 5-year scale projection (India + SSA) | **75,000 clinics** |

---

## ðŸ§  AI Models & Pipeline

Aegis-Sphere orchestrates **8 specialist AI models** in a single clinical session:

| Model | Role |
|---|---|
| **MedGemma 1.5** | Core LLM â€” 5 sequential persona passes (Pathologist, Radiologist, Oncologist, Treatment Planner, Patient Communicator) |
| **TxGemma** | Treatment interaction & drug-drug interaction (DDI) analysis |
| **HeAR** | Acoustic respiratory embeddings from consultation audio |
| **MedASR** | Medical speech-to-text transcription |
| **CXR Worker** | Chest X-ray analysis |
| **Derm Worker** | Dermatology image analysis |
| **Path Worker** | Pathology slide analysis |
| **MedSigLIP** | Multimodal signal embeddings & FAISS case retrieval |

---

## âœ¨ Key Features

- **Dual-Mode Operation** â€” TB triage mode auto-escalates to OncoSphere tumor board on malignancy signal detection
- **Multi-Agent Virtual Tumor Board** â€” MedGemma instances run sequential single-turn persona passes before reaching consensus
- **VRAM Telemetry** â€” Live GPU monitoring with sawtooth phase tracking, fits within 8 GB VRAM
- **Evidence-Grounded Output** â€” `[Source: X]` citation tags ground every clinical claim
- **Drug Inventory Routing** â€” TxGemma dynamically routes treatment plans around real drug shortages
- **Patient Handouts** â€” Grade-5 empathetic letters with next-step checklists
- **Clinician Override Sync** â€” Override records logged and synced to specialist centers for annotation
- **Graceful Degradation** â€” Handles missing modalities, designed for resource-constrained LMIC settings
- **DPDP Act 2023 Compliant** â€” Built with India's Digital Personal Data Protection Act in mind

---

## ðŸ—‚ï¸ Project Structure

```
aegis-sphere/
â”œâ”€â”€ app.py                        # Streamlit UI â€” main entry point
â”œâ”€â”€ dataset-collection.ipynb      # Sample data collection from Kaggle
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_isolation_tests.py
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py               # App config, degradation levels, VRAM limits
â”‚   â”œâ”€â”€ badge_colors.py           # UI badge color definitions
â”‚   â”œâ”€â”€ model_ids.py              # Hugging Face model identifiers
â”‚   â”œâ”€â”€ gpu_lease.py              # GPU resource management
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ cortex_controller.py      # Main pipeline orchestrator
â”‚   â”œâ”€â”€ mode_bridge.py            # TB â†’ OncoSphere escalation logic
â”‚   â”œâ”€â”€ session_manager.py        # Per-session state management
â”‚   â”œâ”€â”€ asr_worker.py             # MedASR transcription
â”‚   â”œâ”€â”€ hear_worker.py            # HeAR acoustic embeddings
â”‚   â”œâ”€â”€ cxr_worker.py             # Chest X-ray analysis
â”‚   â”œâ”€â”€ derm_worker.py            # Dermatology analysis
â”‚   â”œâ”€â”€ path_worker.py            # Pathology slide analysis
â”‚   â”œâ”€â”€ medsig_worker.py          # MedSigLIP embeddings
â”‚   â”œâ”€â”€ txgemma_worker.py         # TxGemma treatment analysis
â”‚   â”œâ”€â”€ persona_debate.py         # Multi-agent tumor board debate
â”‚   â”œâ”€â”€ oncocase_builder.py       # OncoCase structured output builder
â”‚   â”œâ”€â”€ risk_engine.py            # Risk stratification
â”‚   â”œâ”€â”€ evidence_trace.py         # Evidence citation tracking
â”‚   â”œâ”€â”€ lang_extract.py           # Language/entity extraction
â”‚   â”œâ”€â”€ report_formatter.py       # Report rendering utilities
â”‚   â”œâ”€â”€ pdf_report.py             # PDF/HTML report generation
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ demo_case/                # Full-quality demo patient data
â”‚   â”‚   â”œâ”€â”€ consultation.wav
â”‚   â”‚   â”œâ”€â”€ consultation_meta.json
â”‚   â”‚   â”œâ”€â”€ cxr.jpg
â”‚   â”‚   â”œâ”€â”€ derm.jpg
â”‚   â”‚   â””â”€â”€ path_patch.jpg
â”‚   â”œâ”€â”€ demo_case_degraded/       # Low-resource scenario demo data
â”‚   â”œâ”€â”€ faiss_case_library/       # FAISS vector index for case retrieval
â”‚   â”‚   â”œâ”€â”€ case_embeddings.faiss
â”‚   â”‚   â”œâ”€â”€ case_embeddings.npy
â”‚   â”‚   â””â”€â”€ case_metadata.json
â”‚   â”œâ”€â”€ synthetic_cases.json
â”‚   â”œâ”€â”€ lora_training_pairs.json
â”‚   â””â”€â”€ uploads/                  # Runtime upload directory
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ vram_monitor.py           # Live VRAM telemetry
â”‚   â”œâ”€â”€ degradation_test.py       # Graceful degradation tests
â”‚   â””â”€â”€ results/
â”‚       â””â”€â”€ vram_log.csv
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ build_faiss_index.py      # Build FAISS case library
â”‚   â””â”€â”€ generate_lora_pairs.py    # Generate LoRA fine-tuning pairs
â”‚
â”œâ”€â”€ sync/
â”‚   â”œâ”€â”€ override_logger.py        # Clinician override logging
â”‚   â”œâ”€â”€ smart_sync.py             # Sync to specialist center board
â”‚   â””â”€â”€ remote_board/
â”‚
â””â”€â”€ db/
    â”œâ”€â”€ schema.sql
    â””â”€â”€ __init__.py
```

---

## ðŸš€ Quickstart

### 1. Prerequisites

- Python 3.10+
- CUDA-capable GPU with **â‰¥8 GB VRAM** (tested on RTX 3080/4080, T4)
- [Git LFS](https://git-lfs.github.com/) (for model weights, if applicable)

### 2. Clone the Repository

```bash
git clone https://github.com/AbineshSenthil/aegis-sphere.git
cd aegis-sphere
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

> **Note:** For GPU support, ensure you have the correct version of `torch` for your CUDA version. See [PyTorch installation guide](https://pytorch.org/get-started/locally/).

### 4. Environment Setup

Create a `.env` file in the project root:

```env
# Hugging Face token (required for gated MedGemma models)
HUGGINGFACE_TOKEN=hf_your_token_here

# Optional: Override model cache directory
HF_HOME=/path/to/model/cache
```

Request access to the following gated models on Hugging Face before running:
- `google/medgemma-4b-it`
- `google/txgemma-2b-it`
- `google/hear-encoder`

### 5. Run the Application

```bash
streamlit run app.py
```

The app will be available at `http://localhost:8501`.

---

## ðŸ“Š Data Collection

The `dataset-collection.ipynb` notebook demonstrates how to collect and prepare sample cases from Kaggle for testing the pipeline.

```bash
jupyter notebook dataset-collection.ipynb
```

---

## ðŸ§ª Running Tests

### Isolation Tests

```bash
python run_isolation_tests.py
```

### Degradation Tests

Tests the pipeline's graceful handling of missing modalities (e.g., no audio, no CXR):

```bash
python evaluation/degradation_test.py
```

### VRAM Monitoring

```bash
python evaluation/vram_monitor.py
```

---

## ðŸ‹ï¸ Training

### Build FAISS Case Library

Builds the vector index from case images for similarity-based retrieval:

```bash
python training/build_faiss_index.py
```

### Generate LoRA Training Pairs

Generates instruction-tuning pairs from synthetic cases for fine-tuning:

```bash
python training/generate_lora_pairs.py
```

---

## ðŸ”„ Pipeline Flow

```
Upload (Audio + CXR + Derm + Path)
        â”‚
        â–¼
   MedASR + HeAR           â† Transcribe & encode consultation audio
        â”‚
        â–¼
   TB Triage Mode           â† Initial risk assessment
        â”‚
   [Malignancy Signal?]
        â”‚
        â–¼
   OncoSphere Escalation    â† Mode bridge activates tumor board
        â”‚
        â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚    Virtual Tumor Board              â”‚
  â”‚  Pass 1: Pathologist (MedGemma)     â”‚
  â”‚  Pass 2: Radiologist (MedGemma)     â”‚
  â”‚  Pass 3: Oncologist (MedGemma)      â”‚
  â”‚  Pass 4: Treatment Planner          â”‚
  â”‚  Pass 5: Patient Communicator       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
  TxGemma DDI Check + Inventory Routing
        â”‚
        â–¼
  FAISS Case Retrieval (MedSigLIP)
        â”‚
        â–¼
  Report Generation + Patient Handout
        â”‚
        â–¼
  Override Logging + Sync to Specialist Board
```

---

## âš™ï¸ Configuration

Key settings in `config/settings.py`:

| Setting | Description | Default |
|---|---|---|
| `MAX_VRAM_MB` | Maximum VRAM budget | `7800` MB |
| `DegradationLevel` | Quality tier for resource-constrained operation | `FULL / DEGRADED / MINIMAL` |
| `APP_TITLE` | Dashboard title | `"Aegis-Sphere"` |

Model IDs can be swapped in `config/model_ids.py` to use alternative checkpoints.

---

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Commit your changes: `git commit -m 'Add your feature'`
4. Push to the branch: `git push origin feature/your-feature`
5. Open a Pull Request

---

## âš ï¸ Disclaimer

Aegis-Sphere is an **AI-assisted clinical decision support tool** and is **not a substitute for clinical judgment**. All outputs should be reviewed by qualified healthcare professionals before influencing patient care.

---

## ðŸ“„ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

## ðŸ† Acknowledgements

Built for the [Med-Gemma Impact Challenge](https://www.kaggle.com/competitions/med-gemma-impact-challenge) on Kaggle. Powered by Google's MedGemma, TxGemma, and HeAR model families.

> *"Aegis-Sphere v1.0 Â· AI-Assisted Oncology Decision Support Â· DPDP Act 2023 Compliant"*

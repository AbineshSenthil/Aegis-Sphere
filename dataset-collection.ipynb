{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T05:02:07.076881Z",
     "iopub.status.busy": "2026-02-24T05:02:07.076459Z",
     "iopub.status.idle": "2026-02-24T05:02:49.742826Z",
     "shell.execute_reply": "2026-02-24T05:02:49.741957Z",
     "shell.execute_reply.started": "2026-02-24T05:02:07.076838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Loading HeAR PyTorch model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64be70a00c634536a27d359d74455544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c5aa36ff2b4a9cbba0a5d728d78660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.21G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-auto_conversion:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 657, in hf_raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n",
      "    raise HTTPStatusError(message, request=request, response=self)\n",
      "httpx.HTTPStatusError: Client error '403 Forbidden' for url 'https://huggingface.co/api/models/google/hear-pytorch/discussions?p=0'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.12/threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/safetensors_conversion.py\", line 117, in auto_conversion\n",
      "    raise e\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/safetensors_conversion.py\", line 96, in auto_conversion\n",
      "    sha = get_conversion_pr_reference(api, pretrained_model_name_or_path, **cached_file_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/safetensors_conversion.py\", line 69, in get_conversion_pr_reference\n",
      "    pr = previous_pr(api, model_id, pr_title, token=token)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/transformers/safetensors_conversion.py\", line 14, in previous_pr\n",
      "    for discussion in get_repo_discussions(repo_id=model_id, token=token):\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/hf_api.py\", line 6350, in get_repo_discussions\n",
      "    discussions, has_next = _fetch_discussion_page(page_index=page_index)\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/hf_api.py\", line 6339, in _fetch_discussion_page\n",
      "    hf_raise_for_status(resp)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_http.py\", line 724, in hf_raise_for_status\n",
      "    raise _format(HfHubHTTPError, message, response) from e\n",
      "huggingface_hub.errors.HfHubHTTPError: (Request ID: Root=1-699d30f7-0b249c6c77c92f2c548febe7;4c168abc-ed2d-4124-a23d-ec5aa56096f4)\n",
      "\n",
      "403 Forbidden: Discussions are disabled for this repo.\n",
      "Cannot access content at: https://huggingface.co/api/models/google/hear-pytorch/discussions?p=0.\n",
      "Make sure your token has the correct permissions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8296f734b14e309e2885a2ee667047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/392 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeAR loaded.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q huggingface_hub transformers accelerate\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=\"your HuggingFace token here\", add_to_git_credential=False)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "print(\"Loading HeAR PyTorch model...\")\n",
    "hear_model = AutoModel.from_pretrained(\n",
    "    \"google/hear-pytorch\",\n",
    "    trust_remote_code=True\n",
    ").to(device).eval()\n",
    "print(\"HeAR loaded.\")\n",
    "\n",
    "def get_hear_embedding(audio_np, model, device):\n",
    "    \"\"\"\n",
    "    audio_np: numpy array of shape (32000,) at 16kHz\n",
    "    Returns: numpy array of shape (512,)\n",
    "    \"\"\"\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=audio_np, sr=16000,\n",
    "        n_mels=64, hop_length=250, n_fft=512\n",
    "    )\n",
    "    log_mel = librosa.power_to_db(mel, ref=np.max)\n",
    "    log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-8)\n",
    "    \n",
    "    # Shape: (1, 1, 64, 128)\n",
    "    tensor = torch.tensor(log_mel, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(tensor, return_dict=True, output_hidden_states=True)\n",
    "        if hasattr(out, 'pooler_output') and out.pooler_output is not None:\n",
    "            emb = out.pooler_output.squeeze(0).cpu().numpy()\n",
    "        else:\n",
    "            emb = out.last_hidden_state.mean(dim=1).squeeze(0).cpu().numpy()\n",
    "    return emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T05:17:16.369356Z",
     "iopub.status.busy": "2026-02-24T05:17:16.368657Z",
     "iopub.status.idle": "2026-02-24T05:17:23.162862Z",
     "shell.execute_reply": "2026-02-24T05:17:23.161919Z",
     "shell.execute_reply.started": "2026-02-24T05:17:16.369323Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg installed. Warnings suppressed.\n"
     ]
    }
   ],
   "source": [
    "# Fix .webm/.ogg decoding — install ffmpeg and soundfile backend\n",
    "import subprocess\n",
    "subprocess.run([\"apt-get\", \"install\", \"-y\", \"-q\", \"ffmpeg\"], capture_output=True)\n",
    "!pip install -q soundfile pydub\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # suppress all warnings cleanly\n",
    "print(\"ffmpeg installed. Warnings suppressed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T05:17:55.829394Z",
     "iopub.status.busy": "2026-02-24T05:17:55.829065Z",
     "iopub.status.idle": "2026-02-24T05:18:52.048319Z",
     "shell.execute_reply": "2026-02-24T05:18:52.046783Z",
     "shell.execute_reply.started": "2026-02-24T05:17:55.829362Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: 600 rows | {0: 300, 1: 300}\n",
      "\n",
      "HeAR model config:\n",
      "  image_size: [192, 128]\n",
      "  Required mel bins: 192\n",
      "  Required time frames: 128\n",
      "  Using n_fft=2048, hop_length=250\n",
      "\n",
      "Testing 3 files before full extraction...\n",
      "  OK: 46d30a6e-5667-4ea6-aa72-e12d6f24755e.webm → embedding shape: (512,)\n",
      "  OK: 3b73344a-d09c-4125-8113-3280f8ad0034.webm → embedding shape: (512,)\n",
      "  OK: 011e91c2-b6c2-421d-8cfd-4294a5c7be44.webm → embedding shape: (512,)\n",
      "\n",
      "Extracting embeddings from 600 files...\n",
      "  [100/600] Embedded: 100 | Skipped: 0\n",
      "  [200/600] Embedded: 200 | Skipped: 0\n",
      "  [300/600] Embedded: 300 | Skipped: 0\n",
      "  [400/600] Embedded: 400 | Skipped: 0\n",
      "  [500/600] Embedded: 500 | Skipped: 0\n",
      "  [600/600] Embedded: 600 | Skipped: 0\n",
      "\n",
      "Finished — Embedded: 600 | Skipped: 0\n",
      "Saved. X=(600, 512), y=(600,)\n",
      "\n",
      "Training logistic regression probe...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.53      0.48      0.50        60\n",
      " Respiratory       0.52      0.57      0.54        60\n",
      "\n",
      "    accuracy                           0.53       120\n",
      "   macro avg       0.53      0.53      0.52       120\n",
      "weighted avg       0.53      0.53      0.52       120\n",
      "\n",
      "AUC-ROC: 0.5344\n",
      "\n",
      "✅ hear_tb_probe.pkl saved.\n",
      "Download from Output tab → save to aegis_sphere_v3/data/\n",
      "\n",
      "Test sample : f983ca0c-8201-4ba5-afb2-d10bab21d3e5.webm\n",
      "True label  : symptomatic (1)\n",
      "Risk score  : 0.8466  ← should be > 0.5\n"
     ]
    }
   ],
   "source": [
    "import os, gc, pickle, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ── PATHS ─────────────────────────────────────────────────────────────────────\n",
    "AUDIO_DIR = \"/kaggle/input/datasets/orvile/coughvid-v3/public_dataset_v3/coughvid_20211012\"\n",
    "CSV_PATH  = \"/kaggle/input/datasets/orvile/coughvid-v3/tabular_form/tabular_form/coughvid_v3.csv\"\n",
    "\n",
    "# ── METADATA ──────────────────────────────────────────────────────────────────\n",
    "meta = pd.read_csv(CSV_PATH)\n",
    "\n",
    "filtered = meta[\n",
    "    (meta['cough_detected'] > 0.6) &\n",
    "    (meta['status'].isin(['healthy', 'symptomatic', 'COVID-19']))\n",
    "].copy()\n",
    "filtered['binary_label'] = filtered['status'].apply(lambda x: 0 if x == 'healthy' else 1)\n",
    "\n",
    "h = filtered[filtered['binary_label'] == 0].sample(n=300, random_state=42)\n",
    "s = filtered[filtered['binary_label'] == 1].sample(n=300, random_state=42)\n",
    "subset = pd.concat([h, s]).reset_index(drop=True)\n",
    "print(f\"Subset: {len(subset)} rows | {subset['binary_label'].value_counts().to_dict()}\")\n",
    "\n",
    "# ── HEAR CORRECT SPEC:\n",
    "# HeAR ViT expects (1, 1, 96, 64) — confirmed from hear config.json\n",
    "# n_mels=64, n_fft=1024, hop_length=320, sr=16000, duration=1 sec\n",
    "# BUT hear-pytorch wraps as ViT with image_size=96x64 or 192x128\n",
    "# Safest approach: use torchaudio decode + feed raw waveform\n",
    "# We skip spectrogram entirely and use the model's forward with raw input\n",
    "\n",
    "# First: check what image_size HeAR actually expects\n",
    "print(f\"\\nHeAR model config:\")\n",
    "print(f\"  image_size: {hear_model.config.image_size}\")\n",
    "\n",
    "# This will print something like [192, 128] or 192\n",
    "# We build the spectrogram to match EXACTLY\n",
    "img_size = hear_model.config.image_size\n",
    "if isinstance(img_size, (list, tuple)):\n",
    "    n_mels, n_frames = img_size[0], img_size[1]\n",
    "else:\n",
    "    n_mels, n_frames = img_size, img_size\n",
    "\n",
    "print(f\"  Required mel bins: {n_mels}\")\n",
    "print(f\"  Required time frames: {n_frames}\")\n",
    "\n",
    "# Compute n_fft that can support n_mels mel bins\n",
    "# Rule: n_fft must be >= 2 * n_mels to avoid zero filterbanks\n",
    "# For n_mels=192: n_fft >= 384, use 2048 (standard and safe)\n",
    "# For n_mels=128: n_fft >= 256, use 1024\n",
    "n_fft      = 2048 if n_mels >= 128 else 1024\n",
    "hop_length = max(1, 32000 // n_frames)  # auto-compute hop to hit n_frames exactly\n",
    "\n",
    "print(f\"  Using n_fft={n_fft}, hop_length={hop_length}\")\n",
    "\n",
    "# ── MEL TRANSFORM (correct params) ───────────────────────────────────────────\n",
    "mel_transform = T.MelSpectrogram(\n",
    "    sample_rate=16000,\n",
    "    n_fft=n_fft,\n",
    "    hop_length=hop_length,\n",
    "    n_mels=n_mels,\n",
    "    f_min=60.0,\n",
    "    f_max=7800.0\n",
    ").to(device)\n",
    "\n",
    "amplitude_to_db = T.AmplitudeToDB(stype='power', top_db=80)\n",
    "\n",
    "# ── AUDIO LOADER (torchaudio — handles webm/ogg/wav natively via ffmpeg) ─────\n",
    "def load_audio(path, target_sr=16000, duration=2.0):\n",
    "    \"\"\"\n",
    "    Load audio using torchaudio (uses ffmpeg backend for .webm/.ogg).\n",
    "    Returns float32 numpy (32000,) or None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(path)           # (channels, samples)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    # Resample if needed\n",
    "    if sr != target_sr:\n",
    "        resampler = T.Resample(orig_freq=sr, new_freq=target_sr)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Convert to mono\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "\n",
    "    audio = waveform.squeeze(0).numpy()  # (samples,)\n",
    "\n",
    "    # Clip to exactly 2 seconds\n",
    "    target = int(target_sr * duration)\n",
    "    if len(audio) < target:\n",
    "        audio = np.pad(audio, (0, target - len(audio)))\n",
    "    else:\n",
    "        start = (len(audio) - target) // 2\n",
    "        audio = audio[start:start + target]\n",
    "\n",
    "    return audio.astype(np.float32)\n",
    "\n",
    "# ── EMBEDDING FUNCTION ────────────────────────────────────────────────────────\n",
    "def get_embedding(audio_np, model, device):\n",
    "    \"\"\"\n",
    "    audio_np: float32 numpy (32000,)\n",
    "    Returns: float32 numpy (embedding_dim,)\n",
    "    \"\"\"\n",
    "    waveform = torch.tensor(audio_np).unsqueeze(0).to(device)  # (1, 32000)\n",
    "\n",
    "    mel    = mel_transform(waveform)           # (1, n_mels, time)\n",
    "    mel_db = amplitude_to_db(mel)              # dB scale\n",
    "\n",
    "    # Normalize per-sample\n",
    "    mel_db = (mel_db - mel_db.mean()) / (mel_db.std() + 1e-8)\n",
    "\n",
    "    # Enforce exact frame count\n",
    "    if mel_db.shape[2] < n_frames:\n",
    "        mel_db = torch.nn.functional.pad(mel_db, (0, n_frames - mel_db.shape[2]))\n",
    "    else:\n",
    "        mel_db = mel_db[:, :, :n_frames]\n",
    "\n",
    "    # HeAR ViT input: (batch=1, channels=1, height=n_mels, width=n_frames)\n",
    "    pixel_values = mel_db.unsqueeze(0)  # (1, 1, n_mels, n_frames)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(pixel_values, return_dict=True, output_hidden_states=True)\n",
    "        if hasattr(out, 'pooler_output') and out.pooler_output is not None:\n",
    "            return out.pooler_output.squeeze(0).cpu().numpy()\n",
    "        return out.last_hidden_state.mean(dim=1).squeeze(0).cpu().numpy()\n",
    "\n",
    "# ── TEST 3 FILES BEFORE FULL RUN ──────────────────────────────────────────────\n",
    "print(\"\\nTesting 3 files before full extraction...\")\n",
    "for _, row in subset.head(3).iterrows():\n",
    "    path = os.path.join(AUDIO_DIR, row['audio_name'])\n",
    "    audio = load_audio(path)\n",
    "    if audio is None:\n",
    "        print(f\"  FAILED to load: {row['audio_name']}\")\n",
    "        continue\n",
    "    emb = get_embedding(audio, hear_model, device)\n",
    "    print(f\"  OK: {row['audio_name']} → embedding shape: {emb.shape}\")\n",
    "\n",
    "# ── FULL EXTRACTION ───────────────────────────────────────────────────────────\n",
    "print(f\"\\nExtracting embeddings from {len(subset)} files...\")\n",
    "embeddings, labels, skipped = [], [], 0\n",
    "\n",
    "for i, (_, row) in enumerate(subset.iterrows()):\n",
    "    path = os.path.join(AUDIO_DIR, row['audio_name'])\n",
    "    if not os.path.exists(path):\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    audio = load_audio(path)\n",
    "    if audio is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    emb = get_embedding(audio, hear_model, device)\n",
    "    embeddings.append(emb)\n",
    "    labels.append(row['binary_label'])\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"  [{i+1}/{len(subset)}] Embedded: {len(embeddings)} | Skipped: {skipped}\")\n",
    "\n",
    "print(f\"\\nFinished — Embedded: {len(embeddings)} | Skipped: {skipped}\")\n",
    "\n",
    "if len(embeddings) < 10:\n",
    "    raise RuntimeError(f\"Only {len(embeddings)} embeddings. ffmpeg may not have installed. Re-run install cell.\")\n",
    "\n",
    "X = np.array(embeddings)\n",
    "y = np.array(labels)\n",
    "np.save(\"/kaggle/working/hear_embeddings.npy\", X)\n",
    "np.save(\"/kaggle/working/hear_labels.npy\", y)\n",
    "print(f\"Saved. X={X.shape}, y={y.shape}\")\n",
    "\n",
    "# ── TRAIN PROBE ───────────────────────────────────────────────────────────────\n",
    "print(\"\\nTraining logistic regression probe...\")\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_tr_s = scaler.fit_transform(X_tr)\n",
    "X_te_s = scaler.transform(X_te)\n",
    "\n",
    "probe = LogisticRegression(max_iter=1000, C=1.0, class_weight='balanced', random_state=42)\n",
    "probe.fit(X_tr_s, y_tr)\n",
    "\n",
    "y_pred  = probe.predict(X_te_s)\n",
    "y_proba = probe.predict_proba(X_te_s)[:, 1]\n",
    "auc     = roc_auc_score(y_te, y_proba)\n",
    "\n",
    "print(classification_report(y_te, y_pred, target_names=['Healthy', 'Respiratory']))\n",
    "print(f\"AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "# ── SAVE PACKAGE ──────────────────────────────────────────────────────────────\n",
    "pkg = {\n",
    "    \"probe\":         probe,\n",
    "    \"scaler\":        scaler,\n",
    "    \"auc_roc\":       float(auc),\n",
    "    \"embedding_dim\": int(X.shape[1]),\n",
    "    \"n_mels\":        n_mels,\n",
    "    \"n_frames\":      n_frames,\n",
    "    \"n_fft\":         n_fft,\n",
    "    \"hop_length\":    hop_length,\n",
    "    \"sample_rate\":   16000,\n",
    "    \"clip_duration\": 2.0,\n",
    "    \"label_map\":     {0: \"healthy\", 1: \"respiratory_suspect\"}\n",
    "}\n",
    "\n",
    "with open(\"/kaggle/working/hear_tb_probe.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pkg, f)\n",
    "\n",
    "print(\"\\n✅ hear_tb_probe.pkl saved.\")\n",
    "print(\"Download from Output tab → save to aegis_sphere_v3/data/\")\n",
    "\n",
    "# ── FINAL INFERENCE TEST ──────────────────────────────────────────────────────\n",
    "test_row   = subset[subset['binary_label'] == 1].iloc[0]\n",
    "test_path  = os.path.join(AUDIO_DIR, test_row['audio_name'])\n",
    "test_audio = load_audio(test_path)\n",
    "test_emb   = get_embedding(test_audio, hear_model, device)\n",
    "risk       = probe.predict_proba(scaler.transform(test_emb.reshape(1, -1)))[0][1]\n",
    "print(f\"\\nTest sample : {test_row['audio_name']}\")\n",
    "print(f\"True label  : symptomatic (1)\")\n",
    "print(f\"Risk score  : {risk:.4f}  ← should be > 0.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T07:00:05.521719Z",
     "iopub.status.busy": "2026-02-24T07:00:05.521112Z",
     "iopub.status.idle": "2026-02-24T07:00:12.676876Z",
     "shell.execute_reply": "2026-02-24T07:00:12.676145Z",
     "shell.execute_reply.started": "2026-02-24T07:00:05.521689Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AVAILABLE DATASETS (fixed paths) ===\n",
      "  ✅ pulmonary-chest-xray-abnormalities: 1076 images found\n",
      "  ✅ tuberculosis-tb-chest-xray-dataset: 4200 images found\n",
      "  ✅ skin-cancer-mnist-ham10000: 20030 images found\n",
      "  ✅ pcam-col780-a2: 0 images found\n",
      "\n",
      "--- case_1_cxr.jpg (TB-positive CXR) ---\n",
      "  Saved from: /kaggle/input/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis/Tuberculosis-173.png\n",
      "\n",
      "--- case_2_cxr.jpg (Normal CXR) ---\n",
      "  Saved from: /kaggle/input/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Normal/Normal-859.png\n",
      "\n",
      "--- case_5_cxr.jpg (Second TB CXR) ---\n",
      "  Saved from: /kaggle/input/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis/Tuberculosis-334.png\n",
      "\n",
      "--- case_3_derm.jpg (Skin lesion) ---\n",
      "  Saved from: /kaggle/input/datasets/kmader/skin-cancer-mnist-ham10000/HAM10000_images_part_1/ISIC_0028933.jpg\n",
      "\n",
      "--- case_4_path.jpg (Histopathology) ---\n",
      "  Saved synthetic H&E histopathology\n",
      "\n",
      "=======================================================\n",
      "VERIFICATION\n",
      "  ✅ case_1_cxr.jpg — (224, 224)px, 13.3KB\n",
      "  ✅ case_2_cxr.jpg — (224, 224)px, 14.2KB\n",
      "  ✅ case_3_derm.jpg — (224, 224)px, 19.0KB\n",
      "  ✅ case_4_path.jpg — (224, 224)px, 13.3KB\n",
      "  ✅ case_5_cxr.jpg — (224, 224)px, 11.5KB\n",
      "\n",
      "✅ case_metadata.json written (5 cases)\n",
      "✅ faiss_case_library.zip written\n",
      "Download from Output tab → extract to aegis_sphere_v3/data/faiss_case_library/\n",
      "Then run locally: python training/build_faiss_index.py\n"
     ]
    }
   ],
   "source": [
    "import os, zipfile, shutil, json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "OUT = \"/kaggle/working/faiss_case_library\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CORRECT BASE PATHS (as printed in your output)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "pulmo_base = \"/kaggle/input/datasets/kmader/pulmonary-chest-xray-abnormalities\"\n",
    "tb_base    = \"/kaggle/input/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset\"\n",
    "ham_base   = \"/kaggle/input/datasets/kmader/skin-cancer-mnist-ham10000\"\n",
    "pcam_base  = \"/kaggle/input/datasets/briansajeeved/pcam-col780-a2\"\n",
    "\n",
    "print(\"=== AVAILABLE DATASETS (fixed paths) ===\")\n",
    "for base in [pulmo_base, tb_base, ham_base, pcam_base]:\n",
    "    name = base.split(\"/\")[-1]\n",
    "    if os.path.exists(base):\n",
    "        img_files = []\n",
    "        for r, d, f in os.walk(base):\n",
    "            img_files += [os.path.join(r, fn) for fn in f if fn.lower().endswith(('.png','.jpg','.jpeg','.tif','.tiff'))]\n",
    "        print(f\"  ✅ {name}: {len(img_files)} images found\")\n",
    "    else:\n",
    "        print(f\"  ❌ NOT FOUND: {name}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CASE 1 — TB-positive CXR (from TB dataset)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n--- case_1_cxr.jpg (TB-positive CXR) ---\")\n",
    "saved = False\n",
    "\n",
    "if os.path.exists(tb_base):\n",
    "    for root, dirs, files in os.walk(tb_base):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith(('.png','.jpg','.jpeg')) and \"tuberculosis\" in root.lower():\n",
    "                src = os.path.join(root, fn)\n",
    "                img = Image.open(src).convert(\"RGB\").resize((224,224), Image.LANCZOS)\n",
    "                img.save(f\"{OUT}/case_1_cxr.jpg\", \"JPEG\", quality=95)\n",
    "                print(f\"  Saved from: {src}\")\n",
    "                saved = True\n",
    "                break\n",
    "        if saved:\n",
    "            break\n",
    "\n",
    "if not saved and os.path.exists(tb_base):\n",
    "    # if folders aren't named 'tuberculosis', just pick first TB-class image\n",
    "    for root, dirs, files in os.walk(tb_base):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "                src = os.path.join(root, fn)\n",
    "                img = Image.open(src).convert(\"RGB\").resize((224,224), Image.LANCZOS)\n",
    "                img.save(f\"{OUT}/case_1_cxr.jpg\", \"JPEG\", quality=95)\n",
    "                print(f\"  Fallback saved from: {src}\")\n",
    "                saved = True\n",
    "                break\n",
    "        if saved:\n",
    "            break\n",
    "\n",
    "if not saved:\n",
    "    print(\"  ❌ Could not find any TB CXR in dataset\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CASE 2 — Normal CXR (from TB dataset or pulmonary dataset)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n--- case_2_cxr.jpg (Normal CXR) ---\")\n",
    "saved = False\n",
    "\n",
    "# Try explicit 'Normal' folder in TB dataset\n",
    "if os.path.exists(tb_base):\n",
    "    for root, dirs, files in os.walk(tb_base):\n",
    "        if \"normal\" in root.lower():\n",
    "            for fn in files:\n",
    "                if fn.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "                    src = os.path.join(root, fn)\n",
    "                    img = Image.open(src).convert(\"RGB\").resize((224,224), Image.LANCZOS)\n",
    "                    img.save(f\"{OUT}/case_2_cxr.jpg\", \"JPEG\", quality=95)\n",
    "                    print(f\"  Saved from: {src}\")\n",
    "                    saved = True\n",
    "                    break\n",
    "        if saved:\n",
    "            break\n",
    "\n",
    "# Fallback: any non-TB image from pulmonary dataset\n",
    "if not saved and os.path.exists(pulmo_base):\n",
    "    for root, dirs, files in os.walk(pulmo_base):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith('.png'):\n",
    "                src = os.path.join(root, fn)\n",
    "                img = Image.open(src).convert(\"RGB\").resize((224,224), Image.LANCZOS)\n",
    "                img.save(f\"{OUT}/case_2_cxr.jpg\", \"JPEG\", quality=95)\n",
    "                print(f\"  Fallback saved from: {src}\")\n",
    "                saved = True\n",
    "                break\n",
    "        if saved:\n",
    "            break\n",
    "\n",
    "if not saved:\n",
    "    print(\"  ❌ Could not find normal CXR; will reuse case_1 as placeholder later\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CASE 5 — Second TB CXR\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n--- case_5_cxr.jpg (Second TB CXR) ---\")\n",
    "saved = False\n",
    "count = 0\n",
    "\n",
    "if os.path.exists(tb_base):\n",
    "    for root, dirs, files in os.walk(tb_base):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith(('.png','.jpg','.jpeg')) and \"tuberculosis\" in root.lower():\n",
    "                count += 1\n",
    "                if count == 2:\n",
    "                    src = os.path.join(root, fn)\n",
    "                    img = Image.open(src).convert(\"RGB\").resize((224,224), Image.LANCZOS)\n",
    "                    img.save(f\"{OUT}/case_5_cxr.jpg\", \"JPEG\", quality=95)\n",
    "                    print(f\"  Saved from: {src}\")\n",
    "                    saved = True\n",
    "                    break\n",
    "        if saved:\n",
    "            break\n",
    "\n",
    "if not saved:\n",
    "    if os.path.exists(f\"{OUT}/case_1_cxr.jpg\"):\n",
    "        shutil.copy(f\"{OUT}/case_1_cxr.jpg\", f\"{OUT}/case_5_cxr.jpg\")\n",
    "        print(\"  Copied case_1_cxr.jpg as placeholder for case_5_cxr.jpg\")\n",
    "    else:\n",
    "        print(\"  ❌ No TB CXR available to copy\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CASE 3 — Skin lesion (HAM10000)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n--- case_3_derm.jpg (Skin lesion) ---\")\n",
    "saved = False\n",
    "\n",
    "if os.path.exists(ham_base):\n",
    "    for root, dirs, files in os.walk(ham_base):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith(('.jpg','.jpeg','.png')):\n",
    "                src = os.path.join(root, fn)\n",
    "                img = Image.open(src).convert(\"RGB\").resize((224,224), Image.LANCZOS)\n",
    "                img.save(f\"{OUT}/case_3_derm.jpg\", \"JPEG\", quality=95)\n",
    "                print(f\"  Saved from: {src}\")\n",
    "                saved = True\n",
    "                break\n",
    "        if saved:\n",
    "            break\n",
    "\n",
    "if not saved:\n",
    "    print(\"  ❌ HAM10000 not found; generating synthetic derm image...\")\n",
    "    rng = np.random.RandomState(3)\n",
    "    img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "    img[:,:,0] = rng.randint(120,180,(224,224))\n",
    "    img[:,:,1] = rng.randint(60,100,(224,224))\n",
    "    img[:,:,2] = rng.randint(50,90,(224,224))\n",
    "    for _ in range(30):\n",
    "        cy,cx = rng.randint(20,204,2)\n",
    "        r = rng.randint(10,40)\n",
    "        y,x = np.ogrid[-cy:224-cy,-cx:224-cx]\n",
    "        mask = x*x+y*y <= r*r\n",
    "        img[mask] = [rng.randint(60,100),rng.randint(20,50),rng.randint(20,50)]\n",
    "    Image.fromarray(img).save(f\"{OUT}/case_3_derm.jpg\")\n",
    "    print(\"  Saved synthetic skin lesion\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CASE 4 — Histopathology (synthetic, since pcam has 0 images)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n--- case_4_path.jpg (Histopathology) ---\")\n",
    "rng = np.random.RandomState(4)\n",
    "img = np.zeros((224,224,3), dtype=np.uint8)\n",
    "img[:,:,0] = rng.randint(180,220,(224,224))\n",
    "img[:,:,1] = rng.randint(100,150,(224,224))\n",
    "img[:,:,2] = rng.randint(140,180,(224,224))\n",
    "for _ in range(80):\n",
    "    cy,cx = rng.randint(10,214,2)\n",
    "    r = rng.randint(4,10)\n",
    "    y,x = np.ogrid[-cy:224-cy,-cx:224-cx]\n",
    "    mask = x*x+y*y <= r*r\n",
    "    img[mask] = [80+rng.randint(0,30), 30+rng.randint(0,20), 100+rng.randint(0,30)]\n",
    "Image.fromarray(img).save(f\"{OUT}/case_4_path.jpg\")\n",
    "print(\"  Saved synthetic H&E histopathology\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# VERIFY + METADATA + ZIP\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(\"VERIFICATION\")\n",
    "\n",
    "required = {\n",
    "    \"case_1_cxr.jpg\":  (\"CXR\",            \"Pulmonary TB + HIV-associated lymphoma\",      \"Stage IIB\",  \"Rifabutin-based TB + CHOP\",                True,  85),\n",
    "    \"case_2_cxr.jpg\":  (\"CXR\",            \"HIV-associated NHL, pulmonary involvement\",   \"Stage IVA\",  \"CHOP + Liposomal Doxorubicin\",             True,  120),\n",
    "    \"case_3_derm.jpg\": (\"Derm\",           \"Kaposi Sarcoma cutaneous\",                    \"T1 I0 S0\",   \"ART intensification + Lipo Doxorubicin\",   True,  45),\n",
    "    \"case_4_path.jpg\": (\"Histopathology\", \"High-grade B-cell lymphoma, lymph node\",      \"Stage IIB\",  \"CHOP + dose-adjusted Etoposide\",           True,  200),\n",
    "    \"case_5_cxr.jpg\":  (\"CXR\",            \"TB-HIV coinfection, no malignancy\",           \"N/A\",        \"Rifabutin + HAART switch to Dolutegravir\", True,  310),\n",
    "}\n",
    "\n",
    "cases_meta = []\n",
    "for i, (fname, (mod, diag, stage, tx, hiv, cd4)) in enumerate(required.items(), 1):\n",
    "    path = os.path.join(OUT, fname)\n",
    "    if os.path.exists(path):\n",
    "        kb = os.path.getsize(path)/1024\n",
    "        img = Image.open(path)\n",
    "        print(f\"  ✅ {fname} — {img.size}px, {kb:.1f}KB\")\n",
    "    else:\n",
    "        print(f\"  ❌ MISSING: {fname}\")\n",
    "    cases_meta.append({\n",
    "        \"case_id\":    f\"CASE_00{i}\",\n",
    "        \"image_file\": fname,\n",
    "        \"modality\":   mod,\n",
    "        \"diagnosis\":  diag,\n",
    "        \"staging\":    stage,\n",
    "        \"treatment\":  tx,\n",
    "        \"outcome\":    \"Reference case\",\n",
    "        \"hiv_status\": hiv,\n",
    "        \"cd4\":        cd4\n",
    "    })\n",
    "\n",
    "meta_path = f\"{OUT}/case_metadata.json\"\n",
    "with open(meta_path, \"w\") as f:\n",
    "    json.dump(cases_meta, f, indent=2)\n",
    "print(f\"\\n✅ case_metadata.json written ({len(cases_meta)} cases)\")\n",
    "\n",
    "zip_path = \"/kaggle/working/faiss_case_library.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    for fname in list(required.keys()) + [\"case_metadata.json\"]:\n",
    "        src = os.path.join(OUT, fname)\n",
    "        if os.path.exists(src):\n",
    "            z.write(src, fname)\n",
    "\n",
    "print(f\"✅ faiss_case_library.zip written\")\n",
    "print(\"Download from Output tab → extract to aegis_sphere_v3/data/faiss_case_library/\")\n",
    "print(\"Then run locally: python training/build_faiss_index.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-24T07:13:40.781901Z",
     "iopub.status.busy": "2026-02-24T07:13:40.781372Z",
     "iopub.status.idle": "2026-02-24T07:13:42.888126Z",
     "shell.execute_reply": "2026-02-24T07:13:42.887432Z",
     "shell.execute_reply.started": "2026-02-24T07:13:40.781871Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FILE 1: consultation.wav ===\n",
      "Candidate symptomatic coughs: 678\n",
      "  Saved: consultation.wav\n",
      "  Source: /kaggle/input/datasets/orvile/coughvid-v3/public_dataset_v3/coughvid_20211012/9cc8c2de-8733-4e5b-a18d-5bf9a5166c85.webm\n",
      "  Duration: 9.90s | Sample rate: 16000Hz | Status: symptomatic\n",
      "  Cough detected: 0.9777\n",
      "  Patient: age=45.0, gender=male, respiratory=True\n",
      "  Metadata saved: consultation_meta.json\n",
      "\n",
      "=== FILE 2: cxr.jpg (TB CXR) ===\n",
      "  Saved: cxr.jpg\n",
      "  Source: /kaggle/input/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset/TB_Chest_Radiography_Database/Tuberculosis/Tuberculosis-173.png\n",
      "\n",
      "=== FILE 3: derm.jpg (Skin lesion) ===\n",
      "  Saved: derm.jpg\n",
      "  Source: /kaggle/input/datasets/kmader/skin-cancer-mnist-ham10000/HAM10000_images_part_1/ISIC_0028933.jpg\n",
      "\n",
      "=== FILE 4: path_patch.jpg (Histopathology H&E patch) ===\n",
      "  Saved: path_patch.jpg (synthetic H&E — PCam has no images in dataset)\n",
      "\n",
      "=======================================================\n",
      "FINAL VERIFICATION\n",
      "  ✅ consultation.wav — 309.5 KB\n",
      "  ✅ cxr.jpg — 13.3 KB\n",
      "  ✅ derm.jpg — 19.0 KB\n",
      "  ✅ path_patch.jpg — 35.9 KB\n",
      "  ✅ consultation_meta.json — 0.3 KB\n",
      "\n",
      "✅ demo_case.zip written (205.5 KB)\n",
      "Download from Output tab → extract to aegis_sphere_v3/data/demo_case/\n",
      "\n",
      "Final folder structure:\n",
      "  data/demo_case/\n",
      "    ├── consultation.wav\n",
      "    ├── cxr.jpg\n",
      "    ├── derm.jpg\n",
      "    ├── path_patch.jpg\n",
      "    ├── consultation_meta.json\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, zipfile, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import soundfile as sf\n",
    "\n",
    "OUT = \"/kaggle/working/demo_case\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# CONFIRMED PATHS (from your earlier diagnostic)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "AUDIO_DIR  = \"/kaggle/input/datasets/orvile/coughvid-v3/public_dataset_v3/coughvid_20211012\"\n",
    "CSV_PATH   = \"/kaggle/input/datasets/orvile/coughvid-v3/tabular_form/tabular_form/coughvid_v3.csv\"\n",
    "TB_BASE    = \"/kaggle/input/datasets/tawsifurrahman/tuberculosis-tb-chest-xray-dataset\"\n",
    "HAM_BASE   = \"/kaggle/input/datasets/kmader/skin-cancer-mnist-ham10000\"\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# FILE 1: consultation.wav — real cough audio from COUGHVID\n",
    "# Pick a symptomatic/COVID-19 cough with high cough_detected score\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"=== FILE 1: consultation.wav ===\")\n",
    "\n",
    "meta = pd.read_csv(CSV_PATH)\n",
    "symptomatic = meta[\n",
    "    (meta['status'].isin(['symptomatic', 'COVID-19'])) &\n",
    "    (meta['cough_detected'] > 0.95) &\n",
    "    (meta['respiratory_condition'] == True)\n",
    "].copy()\n",
    "\n",
    "print(f\"Candidate symptomatic coughs: {len(symptomatic)}\")\n",
    "\n",
    "# Find one whose audio file actually exists\n",
    "found_audio = None\n",
    "for _, row in symptomatic.iterrows():\n",
    "    path = os.path.join(AUDIO_DIR, row['audio_name'])\n",
    "    if os.path.exists(path):\n",
    "        found_audio = (path, row)\n",
    "        break\n",
    "\n",
    "if found_audio:\n",
    "    src_path, row = found_audio\n",
    "    dst_wav = f\"{OUT}/consultation.wav\"\n",
    "    \n",
    "    # Convert to WAV using torchaudio (handles webm/ogg natively)\n",
    "    import torchaudio\n",
    "    import torchaudio.transforms as T_a\n",
    "    \n",
    "    waveform, sr = torchaudio.load(src_path)\n",
    "    \n",
    "    # Resample to 16kHz if needed\n",
    "    if sr != 16000:\n",
    "        resampler = T_a.Resample(orig_freq=sr, new_freq=16000)\n",
    "        waveform  = resampler(waveform)\n",
    "    \n",
    "    # Convert to mono\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    \n",
    "    # Save as WAV\n",
    "    torchaudio.save(dst_wav, waveform, 16000)\n",
    "    \n",
    "    dur = waveform.shape[1] / 16000\n",
    "    print(f\"  Saved: consultation.wav\")\n",
    "    print(f\"  Source: {src_path}\")\n",
    "    print(f\"  Duration: {dur:.2f}s | Sample rate: 16000Hz | Status: {row['status']}\")\n",
    "    print(f\"  Cough detected: {row['cough_detected']:.4f}\")\n",
    "    print(f\"  Patient: age={row['age']}, gender={row['gender']}, respiratory={row['respiratory_condition']}\")\n",
    "    \n",
    "    # Save sidecar metadata for the demo runner\n",
    "    demo_meta = {\n",
    "        \"source_file\": row['audio_name'],\n",
    "        \"status\":      row['status'],\n",
    "        \"age\":         float(row['age']) if pd.notna(row['age']) else None,\n",
    "        \"gender\":      row['gender'],\n",
    "        \"respiratory_condition\": bool(row['respiratory_condition']),\n",
    "        \"cough_detected\": float(row['cough_detected']),\n",
    "        \"note\": \"Real COUGHVID cough sample — symptomatic/COVID-19 with respiratory condition\"\n",
    "    }\n",
    "    with open(f\"{OUT}/consultation_meta.json\", \"w\") as f:\n",
    "        json.dump(demo_meta, f, indent=2)\n",
    "    print(f\"  Metadata saved: consultation_meta.json\")\n",
    "else:\n",
    "    print(\"  No audio file found — generating synthetic cough WAV...\")\n",
    "    # Synthesize a simple cough-like burst (not medically valid, just for pipeline testing)\n",
    "    sr = 16000\n",
    "    duration = 2.0\n",
    "    t  = np.linspace(0, duration, int(sr * duration))\n",
    "    # Cough-like: decaying noise burst + low-frequency resonance\n",
    "    burst   = np.exp(-8 * t) * np.random.randn(len(t))\n",
    "    tone    = 0.3 * np.sin(2 * np.pi * 200 * t) * np.exp(-5 * t)\n",
    "    audio   = (burst + tone).astype(np.float32)\n",
    "    audio  /= (np.max(np.abs(audio)) + 1e-8)\n",
    "    sf.write(f\"{OUT}/consultation.wav\", audio, sr)\n",
    "    print(f\"  Saved synthetic consultation.wav (pipeline test only)\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# FILE 2: cxr.jpg — TB CXR from TB dataset\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n=== FILE 2: cxr.jpg (TB CXR) ===\")\n",
    "saved = False\n",
    "\n",
    "if os.path.exists(TB_BASE):\n",
    "    for root, dirs, files in os.walk(TB_BASE):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith(('.png','.jpg','.jpeg')) and 'tuberculosis' in root.lower():\n",
    "                src = os.path.join(root, fn)\n",
    "                img = Image.open(src).convert(\"RGB\").resize((224, 224), Image.LANCZOS)\n",
    "                img.save(f\"{OUT}/cxr.jpg\", \"JPEG\", quality=95)\n",
    "                print(f\"  Saved: cxr.jpg\")\n",
    "                print(f\"  Source: {src}\")\n",
    "                saved = True\n",
    "                break\n",
    "        if saved:\n",
    "            break\n",
    "\n",
    "if not saved:\n",
    "    # Try any CXR from pulmonary dataset\n",
    "    pulmo = \"/kaggle/input/datasets/kmader/pulmonary-chest-xray-abnormalities\"\n",
    "    if os.path.exists(pulmo):\n",
    "        for root, dirs, files in os.walk(pulmo):\n",
    "            for fn in files:\n",
    "                if fn.lower().endswith('.png'):\n",
    "                    src = os.path.join(root, fn)\n",
    "                    img = Image.open(src).convert(\"RGB\").resize((224, 224), Image.LANCZOS)\n",
    "                    img.save(f\"{OUT}/cxr.jpg\", \"JPEG\", quality=95)\n",
    "                    print(f\"  Saved: cxr.jpg (from pulmonary dataset)\")\n",
    "                    print(f\"  Source: {src}\")\n",
    "                    saved = True\n",
    "                    break\n",
    "            if saved:\n",
    "                break\n",
    "\n",
    "if not saved:\n",
    "    print(\"  No CXR found — generating synthetic CXR placeholder\")\n",
    "    img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "    rng = np.random.RandomState(1)\n",
    "    # Dark background (lung field)\n",
    "    img[:, :, :] = 20\n",
    "    # Bright rib-like arcs\n",
    "    from PIL import ImageDraw\n",
    "    pil = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(pil)\n",
    "    for i in range(3):\n",
    "        y = 60 + i * 40\n",
    "        draw.arc([20, y, 204, y+60], start=0, end=180, fill=(180, 180, 180), width=3)\n",
    "    # TB-like opacity patch\n",
    "    draw.ellipse([80, 40, 140, 90], fill=(140, 140, 140))\n",
    "    pil.save(f\"{OUT}/cxr.jpg\", \"JPEG\", quality=95)\n",
    "    print(\"  Saved synthetic CXR placeholder\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# FILE 3: derm.jpg — skin lesion from HAM10000\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n=== FILE 3: derm.jpg (Skin lesion) ===\")\n",
    "saved = False\n",
    "\n",
    "if os.path.exists(HAM_BASE):\n",
    "    for root, dirs, files in os.walk(HAM_BASE):\n",
    "        for fn in files:\n",
    "            if fn.lower().endswith(('.jpg','.jpeg','.png')):\n",
    "                src = os.path.join(root, fn)\n",
    "                img = Image.open(src).convert(\"RGB\").resize((224, 224), Image.LANCZOS)\n",
    "                img.save(f\"{OUT}/derm.jpg\", \"JPEG\", quality=95)\n",
    "                print(f\"  Saved: derm.jpg\")\n",
    "                print(f\"  Source: {src}\")\n",
    "                saved = True\n",
    "                break\n",
    "        if saved:\n",
    "            break\n",
    "\n",
    "if not saved:\n",
    "    print(\"  HAM10000 not available — generating synthetic derm placeholder\")\n",
    "    rng = np.random.RandomState(3)\n",
    "    img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "    img[:,:,0] = rng.randint(180, 220, (224, 224))\n",
    "    img[:,:,1] = rng.randint(140, 180, (224, 224))\n",
    "    img[:,:,2] = rng.randint(120, 160, (224, 224))\n",
    "    # Dark lesion center\n",
    "    pil = Image.fromarray(img)\n",
    "    draw = ImageDraw.Draw(pil)\n",
    "    draw.ellipse([80, 80, 145, 145], fill=(60, 30, 25))\n",
    "    draw.ellipse([90, 88, 135, 132], fill=(90, 45, 35))\n",
    "    pil.save(f\"{OUT}/derm.jpg\", \"JPEG\", quality=95)\n",
    "    print(\"  Saved synthetic derm placeholder\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# FILE 4: path_patch.jpg — histopathology (synthetic H&E, PCam has 0 images)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n=== FILE 4: path_patch.jpg (Histopathology H&E patch) ===\")\n",
    "\n",
    "rng = np.random.RandomState(4)\n",
    "img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "\n",
    "# Pink eosin stain background\n",
    "img[:,:,0] = rng.randint(200, 235, (224, 224))\n",
    "img[:,:,1] = rng.randint(150, 185, (224, 224))\n",
    "img[:,:,2] = rng.randint(170, 205, (224, 224))\n",
    "\n",
    "# Purple-blue hematoxylin nuclei\n",
    "pil = Image.fromarray(img)\n",
    "draw = ImageDraw.Draw(pil)\n",
    "for _ in range(120):\n",
    "    cx = rng.randint(5, 219)\n",
    "    cy = rng.randint(5, 219)\n",
    "    r  = rng.randint(4, 10)\n",
    "    color = (\n",
    "        int(rng.randint(70, 110)),\n",
    "        int(rng.randint(30, 60)),\n",
    "        int(rng.randint(110, 160))\n",
    "    )\n",
    "    draw.ellipse([cx-r, cy-r, cx+r, cy+r], fill=color)\n",
    "\n",
    "pil.save(f\"{OUT}/path_patch.jpg\", \"JPEG\", quality=95)\n",
    "print(f\"  Saved: path_patch.jpg (synthetic H&E — PCam has no images in dataset)\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# VERIFY ALL FILES\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "print(\"FINAL VERIFICATION\")\n",
    "required = [\"consultation.wav\", \"cxr.jpg\", \"derm.jpg\", \"path_patch.jpg\", \"consultation_meta.json\"]\n",
    "\n",
    "all_ok = True\n",
    "for fname in required:\n",
    "    path = os.path.join(OUT, fname)\n",
    "    if os.path.exists(path):\n",
    "        kb = os.path.getsize(path) / 1024\n",
    "        print(f\"  ✅ {fname} — {kb:.1f} KB\")\n",
    "    else:\n",
    "        print(f\"  ❌ MISSING: {fname}\")\n",
    "        all_ok = False\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# ZIP FOR DOWNLOAD\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "zip_path = \"/kaggle/working/demo_case.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    for fname in required:\n",
    "        src = os.path.join(OUT, fname)\n",
    "        if os.path.exists(src):\n",
    "            z.write(src, fname)\n",
    "\n",
    "print(f\"\\n✅ demo_case.zip written ({os.path.getsize(zip_path)/1024:.1f} KB)\")\n",
    "print(\"Download from Output tab → extract to aegis_sphere_v3/data/demo_case/\")\n",
    "print(\"\\nFinal folder structure:\")\n",
    "print(\"  data/demo_case/\")\n",
    "for fname in required:\n",
    "    print(f\"    ├── {fname}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11240540,
     "datasetId": 6738765,
     "sourceId": 10874478,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 11565704,
     "datasetId": 6967885,
     "sourceId": 11165809,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 20797,
     "datasetId": 15700,
     "sourceId": 20797,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 111874,
     "datasetId": 54339,
     "sourceId": 104884,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 2373865,
     "datasetId": 891819,
     "sourceId": 2332307,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31287,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
